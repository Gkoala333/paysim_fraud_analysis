# PaySim Fraud Detection Configuration

# Data Paths
data:
  raw_data: "data/paysim_fraud.csv"
  processed_data: "data/processed/"
  tableau_exports: "data/tableau_exports/"
  
# Processing Settings
processing:
  chunk_size: 100000  # Process data in chunks for memory efficiency
  n_jobs: -1  # Use all available CPU cores
  random_state: 42
  test_size: 0.2
  
# Data Cleaning
cleaning:
  remove_duplicates: true
  handle_missing: "auto"  # auto, drop, fill
  fill_strategy: "median"  # mean, median, mode, zero
  outlier_method: "iqr"  # iqr, zscore, isolation_forest
  outlier_threshold: 3.0
  balance_tolerance: 0.01  # Tolerance for balance validation

# Transaction Types
transaction_types:
  - PAYMENT
  - TRANSFER
  - CASH_OUT
  - CASH_IN
  - DEBIT

# Analysis Settings
analysis:
  fraud_threshold: 0.95  # Confidence threshold for fraud detection
  min_transaction_amount: 0
  max_transaction_amount: null  # null = no limit
  correlation_method: "pearson"  # pearson, spearman, kendall
  
  # Risk scoring weights
  risk_weights:
    amount: 0.30
    balance_change: 0.25
    transaction_type: 0.20
    time_pattern: 0.15
    network_pattern: 0.10

# Feature Engineering
features:
  create_time_features: true
  create_balance_features: true
  create_network_features: true
  create_statistical_features: true
  
  # Additional features
  include:
    - amount_log
    - balance_ratio
    - transaction_frequency
    - amount_deviation
    - time_of_day
    - day_of_week

# Visualization Settings
visualization:
  style: "seaborn"
  context: "notebook"
  palette: "viridis"
  figure_size: [12, 8]
  dpi: 300
  save_format: "png"

# Tableau Export Settings
tableau:
  export_format: "csv"  # csv, parquet, excel
  max_rows: 1000000  # Limit for Tableau Public
  include_aggregated: true
  aggregation_levels:
    - hourly
    - daily
    - by_type
    - by_risk_level
  
  # Export datasets
  exports:
    - name: "transactions_full"
      description: "Complete transaction dataset"
      enabled: true
    
    - name: "fraud_summary"
      description: "Aggregated fraud statistics"
      enabled: true
    
    - name: "risk_segments"
      description: "Transaction risk segmentation"
      enabled: true
    
    - name: "time_series"
      description: "Time-based aggregations"
      enabled: true
    
    - name: "correlation_matrix"
      description: "Feature correlations"
      enabled: true

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "[{time:YYYY-MM-DD HH:mm:ss}] {level} | {message}"
  output: "outputs/logs/fraud_detection.log"
  rotation: "500 MB"
  retention: "30 days"

# Output Settings
output:
  figures_dir: "outputs/figures/"
  reports_dir: "outputs/reports/"
  logs_dir: "outputs/logs/"
  save_intermediate: true
  overwrite_existing: false

# Performance Optimization
performance:
  use_dask: false  # Enable for very large datasets
  optimize_dtypes: true
  use_categorical: true
  cache_processed: true

# Dashboard Specifications
dashboard:
  refresh_interval: 3600  # seconds
  auto_refresh: false
  
  # KPIs
  kpis:
    - total_transactions
    - fraud_rate
    - total_fraud_amount
    - detection_rate
    - false_positive_rate
    - avg_transaction_amount
  
  # Filters
  filters:
    - transaction_type
    - time_range
    - amount_range
    - risk_level

# Alerts
alerts:
  enabled: true
  thresholds:
    fraud_rate_spike: 0.05  # Alert if fraud rate increases by 5%
    large_transaction: 200000  # Alert for transactions over this amount
    suspicious_pattern_score: 0.90

# Model Settings (for future ML integration)
model:
  algorithms:
    - logistic_regression
    - random_forest
    - xgboost
    - isolation_forest
  
  cross_validation:
    n_splits: 5
    shuffle: true
  
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - roc_auc
    - confusion_matrix

# Testing
testing:
  run_data_validation: true
  sample_size: 1000
  validate_outputs: true
